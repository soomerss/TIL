# BeautifulSoup

## 설치방법
- pip install BeautifulSoup4

## BeautifulSoup 객체만들기
- html파일을 넣어 객체를 만든다.
- 통상 soup 변수에 해당 객체를 만들어 사용하고, 이 soup을 통해 원하는 자료를 찾는다.
```python
import requests
from bs4 import BeautifulSoup

res = requests.get('https://www.naver.com')
soup = BeautifulSoup(res.content,'html.parser')
```

## Soup변수 다루기
- soup.prettify() > HTML 파일을 보기 편하게 반환
- soup.head, soup.body > HTML파일의 head태그와 Body태그를 가져옴
- soup.find(태그), soup.find_all(태그) > 가져오고 싶은 태그 하나 또는 전체(리스트)
- 가져온 태그의 이름 : .name, 내용 : .text 로 확인 가능
- soup.select('CSS_SELECTOR')를 하게 되면 가져오고 싶은 태그의 CSS셀렉터의 정보를 '리스트'에 담아 가져온다.
- soup.select_one('CSS_SELECTOR')를 하게 되면 가져오고 싶은 태그의 객체를 반환한다.

## 페이지네이션
- 반복문으로 블로그의 페이지 정보를 가져올 수 있다.

## 프로그래머스 커뮤니티의 태그 정보를 크롤링하는 예시

```python
from bs4 import BeautifulSoup
import requests

def get_question(soup):
    questions = soup.select('div.question ul.question-tags a span')
    return questions

def make_count(questions,question_count):
    for question in questions:
        question_count[question.text] = question_count.get(question.text,0) + 1

question_count = dict()
for i in range(250):
    if i == 0:
        url = 'https://qna.programmers.co.kr/'
        res = requests.get(url,headers=user_agent)
        if res.status_code == 200:
            soup = BeautifulSoup(res.content,'html.parser')
            questions = get_question(soup)
            make_count(questions,question_count)
        else : 
            break
    else :
        url = f'https://qna.programmers.co.kr/?page={i+1}'
        res = requests.get(url,headers=user_agent)
        if res.status_code == 200:
            soup = BeautifulSoup(res.content,'html.parser')
            questions = get_question(soup)
            make_count(questions,question_count)
        else :
            break
```            
## 한계
- 정적 웹페이지만을 온전하게 크롤링할 수 있다.
- 동적 웹페이지는 어렵다.
- 태그의 클릭 및 키보드를 사용하는 크롤링은 할 수 없다.